{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01d2368e",
   "metadata": {},
   "source": [
    "# HW1\n",
    "## Jie Liu, Xuening Li, Jiamin Zhu, Lemeng zhou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "faafcaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats                 \n",
    "from scipy.stats import norm\n",
    "import datetime\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "001ed5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 10     # sets viewing configuration for easier readability in the console"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ccf905da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== FUNCTION DEFINITIONS ==========\n",
    "def proportion(array_TF):\n",
    "    return sum(array_TF)/len(array_TF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4e49bf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_zscore(phat, p_f, n_f):\n",
    "    z_score_f = (phat-p_f)/((p_f*(1-p_f))/n_f)**0.5     ##### Replace None with formula\n",
    "    return z_score_f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "54a1376b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_z_crit_value(alpha_f, num_sides_f):\n",
    "    z_crit_value_f = norm.ppf(1-(alpha_f/num_sides_f))   ##### Replace None with formula; hint: use norm.ppf package\n",
    "    return z_crit_value_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f0db608f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_p_value(zscore_f, num_sides_f):\n",
    "    ### p_value_f = (1-norm.cdf(zscore_f))/num_sides_f\n",
    "    p_value_f = num_sides_f * min(norm.cdf(zscore_f), 1 - norm.cdf(zscore_f)) ##### Replace None with formula; hint: use norm.cdf package\n",
    "    return p_value_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "37bb450b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reject_null(variantA_outcomes_f, variantB_outcomes_f, alpha_f, num_sides_f):\n",
    "    p_hat_f = proportion(variantB_outcomes_f)\n",
    "    p_f = proportion(variantA_outcomes_f)\n",
    "    n_f = len(variantB_outcomes_f)\n",
    "    z_score = calc_zscore(p_hat_f, p_f, n_f)\n",
    "    p_value = get_p_value(z_score, num_sides_f)\n",
    "    z_crit = get_z_crit_value(alpha_f, num_sides_f)\n",
    "    \n",
    "    ##### reject_null_TF_f = None         \n",
    "    ##### Replace None with formula. This should result in a boolean variable (True or False). You can check the variable type in the console with the command: \"type(reject_null_TF_f)\"\n",
    "    if z_score >= z_crit and p_value < alpha_f:\n",
    "    # if z_score >= z_crit:\n",
    "        reject_null_TF_f = True\n",
    "    else:\n",
    "        reject_null_TF_f = False\n",
    "\n",
    "    return reject_null_TF_f, z_score, p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8807206a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_optimal_sample_size(p0_f, mde_f, alpha_f, power_f):\n",
    "    t_alpha2 = abs(norm.ppf(alpha_f/2))\n",
    "    t_beta = abs(norm.ppf(1-power_f))\n",
    "    p1_f = p0_f + mde_f\n",
    "    p_avg = (p0_f + (p0_f + mde_f))/2\n",
    "    sample_size = pow((t_alpha2*(pow(2*p_avg*(1-p_avg), 0.5)) + t_beta*pow((p0_f*(1-p0_f)+p1_f*(1-p1_f)), 0.5)), 2)*(1/pow(mde_f, 2)) ##### Replace None with formula\n",
    "    return sample_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "da94be69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DECLARE PARAMETERS\n",
    "\n",
    "\n",
    "trial_start_date=datetime.date(year=2020, month=8, day=1)\n",
    "\n",
    "#LOAD DATA\n",
    "df = pd.read_csv('AB_test_data.csv')\n",
    "df.date = pd.to_datetime(df.date, format='%Y-%m-%d')    # parse string format\n",
    "df.date = df.date.apply(lambda x: datetime.date(year=x.year, month=x.month, day=x.day)) # convert to standard (non-pandas) format for comparison against other dates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8910aa50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>purchase_TF</th>\n",
       "      <th>Variant</th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>A</td>\n",
       "      <td>2019-11-08</td>\n",
       "      <td>0x25b44a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>B</td>\n",
       "      <td>2020-08-27</td>\n",
       "      <td>0x46271e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>A</td>\n",
       "      <td>2020-06-11</td>\n",
       "      <td>0x80b8f1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>B</td>\n",
       "      <td>2020-08-22</td>\n",
       "      <td>0x8d736d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>A</td>\n",
       "      <td>2020-08-05</td>\n",
       "      <td>0x96c9c8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   purchase_TF Variant        date        id\n",
       "0        False       A  2019-11-08  0x25b44a\n",
       "1        False       B  2020-08-27  0x46271e\n",
       "2        False       A  2020-06-11  0x80b8f1\n",
       "3        False       B  2020-08-22  0x8d736d\n",
       "4        False       A  2020-08-05  0x96c9c8"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0a029577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== ANALYSES ==========\n",
    "# ----- Get summary stats -----\n",
    "df['year'] = pd.DatetimeIndex(df['date']).year\n",
    "df['month'] = pd.DatetimeIndex(df['date']).month\n",
    "df_summary = df[['year', 'month', 'Variant', 'id', 'purchase_TF']].groupby(['year', 'month', 'Variant']).agg({'id': 'count', 'purchase_TF': 'sum'}).rename(columns={'id': 'num_exposures', 'purchase_TF': 'num_bookings'})\n",
    "df_summary['conv_rate'] = df_summary['num_bookings']/df_summary['num_exposures']\n",
    "perc_vA = df_summary.loc[(trial_start_date.year, trial_start_date.month, 'A'), 'num_bookings'] / df_summary.loc[(trial_start_date.year, trial_start_date.month, 'A'), 'num_exposures']\n",
    "perc_vB = df_summary.loc[(trial_start_date.year, trial_start_date.month, 'B'), 'num_bookings'] / df_summary.loc[(trial_start_date.year, trial_start_date.month, 'B'), 'num_exposures']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c2fd8ee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>num_exposures</th>\n",
       "      <th>num_bookings</th>\n",
       "      <th>conv_rate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>Variant</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2019</th>\n",
       "      <th>8</th>\n",
       "      <th>A</th>\n",
       "      <td>10176</td>\n",
       "      <td>1523</td>\n",
       "      <td>0.149666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <th>A</th>\n",
       "      <td>9810</td>\n",
       "      <td>1498</td>\n",
       "      <td>0.152701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <th>A</th>\n",
       "      <td>10179</td>\n",
       "      <td>1532</td>\n",
       "      <td>0.150506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <th>A</th>\n",
       "      <td>9957</td>\n",
       "      <td>1398</td>\n",
       "      <td>0.140404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <th>A</th>\n",
       "      <td>10249</td>\n",
       "      <td>1493</td>\n",
       "      <td>0.145673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">2020</th>\n",
       "      <th>1</th>\n",
       "      <th>A</th>\n",
       "      <td>10248</td>\n",
       "      <td>1558</td>\n",
       "      <td>0.152030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>A</th>\n",
       "      <td>9446</td>\n",
       "      <td>1387</td>\n",
       "      <td>0.146835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>A</th>\n",
       "      <td>10021</td>\n",
       "      <td>1488</td>\n",
       "      <td>0.148488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>A</th>\n",
       "      <td>9780</td>\n",
       "      <td>1539</td>\n",
       "      <td>0.157362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <th>A</th>\n",
       "      <td>10162</td>\n",
       "      <td>1538</td>\n",
       "      <td>0.151348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <th>A</th>\n",
       "      <td>9856</td>\n",
       "      <td>1460</td>\n",
       "      <td>0.148133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <th>A</th>\n",
       "      <td>10116</td>\n",
       "      <td>1514</td>\n",
       "      <td>0.149664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">8</th>\n",
       "      <th>A</th>\n",
       "      <td>5000</td>\n",
       "      <td>774</td>\n",
       "      <td>0.154800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>5000</td>\n",
       "      <td>883</td>\n",
       "      <td>0.176600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    num_exposures  num_bookings  conv_rate\n",
       "year month Variant                                        \n",
       "2019 8     A                10176          1523   0.149666\n",
       "     9     A                 9810          1498   0.152701\n",
       "     10    A                10179          1532   0.150506\n",
       "     11    A                 9957          1398   0.140404\n",
       "     12    A                10249          1493   0.145673\n",
       "2020 1     A                10248          1558   0.152030\n",
       "     2     A                 9446          1387   0.146835\n",
       "     3     A                10021          1488   0.148488\n",
       "     4     A                 9780          1539   0.157362\n",
       "     5     A                10162          1538   0.151348\n",
       "     6     A                 9856          1460   0.148133\n",
       "     7     A                10116          1514   0.149664\n",
       "     8     A                 5000           774   0.154800\n",
       "           B                 5000           883   0.176600"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ff7f8e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For month beginning 2020-08-01, Variant A had 5000 exposures (15.5%) and Variant B had 5000 exposures (17.7%)\n"
     ]
    }
   ],
   "source": [
    "print('For month beginning %s, Variant A had %d exposures (%3.1f%%) and Variant B had %d exposures (%3.1f%%)' % (trial_start_date, int(df_summary.loc[(trial_start_date.year, trial_start_date.month, 'A'), 'num_exposures']), perc_vA*100, int(df_summary.loc[(trial_start_date.year, trial_start_date.month, 'B'), 'num_exposures']), perc_vB*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "40eaf5e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion rate for Variant A: 15.0%\n",
      "Conversion rate for Variant B: 17.7%\n",
      "Using all Variant B, reject null T/F?: True\n",
      "z-score = 5.35 and p-value = 0.000004415%\n"
     ]
    }
   ],
   "source": [
    "# Question 1\n",
    "# set parameters\n",
    "alpha = 0.05    # significance level\n",
    "num_sides = 1   # one-sided=1 or two-sided=2 test\n",
    "\n",
    "\n",
    "# ALL DATA\n",
    "variantA_outcomes = df.loc[df['Variant'] == 'A', 'purchase_TF']\n",
    "variantB_outcomes = df.loc[df['Variant'] == 'B', 'purchase_TF']\n",
    "\n",
    "#conduct tests\n",
    "reject_null_test, z_score, p_value = reject_null(variantA_outcomes, variantB_outcomes, alpha, num_sides)\n",
    "print('Conversion rate for Variant A: %3.1f%%' % (proportion(variantA_outcomes)*100))\n",
    "print('Conversion rate for Variant B: %3.1f%%' % (proportion(variantB_outcomes)*100))\n",
    "print('Using all Variant B, reject null T/F?: %s' % reject_null_test)\n",
    "print('z-score = %3.2f and p-value = %3.9f%%' % (z_score, p_value*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "be63c655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal sample size is 2395 \n",
      "For 10 samples of optimal sample size 2395, 100.00% rejected the null\n",
      "   sample number   z_score   p_value\n",
      "0              0  2.048038  0.020278\n",
      "1              1  3.121374  0.000900\n",
      "2              2  3.516813  0.000218\n",
      "3              3  3.516813  0.000218\n",
      "4              4  3.686287  0.000114\n",
      "5              5  2.330495  0.009890\n",
      "6              6  3.403830  0.000332\n",
      "7              7  4.138218  0.000018\n",
      "8              8  3.686287  0.000114\n",
      "9              9  3.799270  0.000073\n"
     ]
    }
   ],
   "source": [
    "# ----- Question 2 -----\n",
    "# set parameters\n",
    "alpha = 0.05    # significance level\n",
    "power = 0.80    # power of test\n",
    "mde = 0.03      # desired minimum detectable effect\n",
    "num_sides = 1   # one-sided or two-sided test\n",
    "\n",
    "# --- Configure data\n",
    "variantA_outcomes_control = df.loc[(df['Variant'] == 'A') & (df.date < trial_start_date), 'purchase_TF']\n",
    "variantA_outcomes = df.loc[(df['Variant'] == 'A') & (df.date >= trial_start_date), 'purchase_TF']\n",
    "variantB_outcomes = df.loc[(df['Variant'] == 'B') & (df.date >= trial_start_date), 'purchase_TF']\n",
    "\n",
    "# --- Calculate and display the optimal sample size\n",
    "p0 = proportion(variantA_outcomes_control)     # this would be the baseline prior to starting a test since we would only have historical information\n",
    "n_star = int(np.ceil(calc_optimal_sample_size(p0, mde, alpha, power)))    # optimal sample size; rounding up using np.ceil because sample must be a whole number that is *at least* as large as the optimal size\n",
    "num_samples = 10\n",
    "\n",
    "\n",
    "print('The optimal sample size is %d ' % n_star)\n",
    "if n_star > variantB_outcomes.shape[0]:\n",
    "    print('Warning: optimal sample size is larger than number of observations.')\n",
    "\n",
    "# --- conduct test for n samples of the optimal size\n",
    "# initialize list to store variables from each loop iteration\n",
    "variantB_outcomes_samples = list()  # this will store the data samples\n",
    "reject_null_list = list()   # this will store the results of the significance tests\n",
    "z_score_list = list()   # this still store the z-scores from each test\n",
    "p_value_list = list()   # this will store the p-values from each test\n",
    "for i in range(0, num_samples):\n",
    "    t_perc_of_trial_data_to_use = n_star/variantB_outcomes.shape[0]  ##### Replace None with the formula for what percent of the trial data should be used\n",
    "    t_sample = variantB_outcomes.sample(frac=min(t_perc_of_trial_data_to_use, 1))   ##### No changes needed, but think about why we're using a min() function here\n",
    "    t_reject, t_z_score, t_p_value = reject_null(variantA_outcomes, t_sample, alpha, num_sides)\n",
    "    variantB_outcomes_samples.append(list(t_sample))    ##### No changes needed, but investigate what the append function is doing here\n",
    "    reject_null_list.append(t_reject)\n",
    "    z_score_list.append(t_z_score)\n",
    "    p_value_list.append(t_p_value)\n",
    "    \n",
    "\n",
    "print(\"For %d samples of optimal sample size %d, %3.2f%% rejected the null\" % (num_samples, n_star, proportion(reject_null_list)*100))\n",
    "\n",
    "df_sample_summary = pd.DataFrame(data={'sample number': list(range(0, num_samples)), 'z_score': z_score_list, 'p_value': p_value_list})\n",
    "print(df_sample_summary[['sample number', 'z_score', 'p_value']])\n",
    "df_sample_summary.to_csv('sample_summary.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "efbc0d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d21a2c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters\n",
    "upp_bdr = math.log(1/alpha) \n",
    "lower_bdr = math.log(1-power)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0319729c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample  1 , trail 402 , rejecting H0\n",
      "ln lambda is 3.0237460723853524\n",
      "Sample  2 , trail 641 , rejecting H0\n",
      "ln lambda is 3.050257452502628\n",
      "Sample  3 , trail 558 , rejecting H0\n",
      "ln lambda is 3.001960094307472\n",
      "Sample  4 , trail 64 , not rejecting H0\n",
      "ln lambda is -1.650732726708318\n",
      "Sample  5 , trail 2174 , rejecting H0\n",
      "ln lambda is 3.062218249010228\n",
      "Sample  6 , trail 125 , rejecting H0\n",
      "ln lambda is 3.0855494812917117\n",
      "Sample  7 , trail 352 , rejecting H0\n",
      "ln lambda is 3.0843246663171344\n",
      "Sample  8 , trail 348 , rejecting H0\n",
      "ln lambda is 3.07276068510955\n",
      "Sample  9 , trail 871 , rejecting H0\n",
      "ln lambda is 3.0217694194872404\n",
      "Sample  10 , trail 460 , rejecting H0\n",
      "ln lambda is 3.0456088493159474\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "ln_val = 0\n",
    "cnt = 0 ## how many samples have been tested\n",
    "num = 0 ## sum of trails in each test\n",
    "\n",
    "#conduct 10 sequential tests \n",
    "for i in range(10):\n",
    "    ln_lambda = 0\n",
    "    j = 0\n",
    "    A_data = df[df['Variant']=='A'].sample(n=n_star, random_state=i*1000, axis=None)\n",
    "    mean_A = np.mean(A_data['purchase_TF'])\n",
    "    B_data = df[df['Variant']=='B'].sample(n=n_star, random_state=i*1000, axis=None)\n",
    "    mean_B = np.mean(B_data['purchase_TF'])\n",
    "    for x in range(2400):\n",
    "        d = int(B_data['purchase_TF'][j:j+1]) \n",
    "        if d == 1:\n",
    "            ln_val = math.log(mean_B/mean_A)\n",
    "        elif d < 1:\n",
    "            ln_val = math.log((1-mean_B)/(1-mean_A))\n",
    "        ln_lambda += ln_val\n",
    "        if ln_lambda <= lower_bdr:\n",
    "            print('Sample ',i+1,', trail' ,j ,', not rejecting H0')\n",
    "            print('ln lambda is', ln_lambda)\n",
    "            cnt += j\n",
    "            break\n",
    "        elif ln_lambda >= upp_bdr:\n",
    "            print('Sample ',i+1,', trail' ,j ,', rejecting H0')\n",
    "            print('ln lambda is',ln_lambda)\n",
    "            cnt += j\n",
    "            break\n",
    "            \n",
    "        j += 1\n",
    "    num += j\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "84b2cbef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On average, 600  iterations are needed to stop the test.\n"
     ]
    }
   ],
   "source": [
    "print('On average,', round(num/10),' iterations are needed to stop the test.')  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463be76d",
   "metadata": {},
   "source": [
    "As we can see from above results, it is possible to stop the test before going through all the samples.\n",
    "One-sided test helps to check if the critical area of a distribution is either greater than or less \n",
    "than a certain value, but not both. \n",
    "Sequential A/B testing helped us to reduce the number samples required.\n",
    "On average,600  iterations are needed to stop the test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7e8108",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
